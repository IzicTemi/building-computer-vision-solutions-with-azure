{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please install the required Python modules/SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! activate ai-azure-c1\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/opt/conda/envs/ai-azure-c1/lib/python3.8/site-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Useful Python Libraries or package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilitiy Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_in_cell(face_url):\n",
    "    response = requests.get(face_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_object_in_cell(image_object):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(image_object)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKEN FROM THE Azure SDK Sample\n",
    "# Convert width height to a point in a rectangle\n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "    \n",
    "    return ((left, top), (right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawFaceRectangles(source_file, datected_face_object) :\n",
    "    # Download the image from the url\n",
    "    response = requests.get(source_file)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    # Draw a red box around every detected faces\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for face in datected_face_object:\n",
    "        draw.rectangle(getRectangle(face), outline='red', width = 10)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Specific Azure Resources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = \"ENTER FACE SERVICE RESOURCE KEY\"\n",
    "ENDPOINT = \"ENTER FACE SERVICE RESOURCE ENDPOINT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distracted driver image to show the changes in headpose in comparision with straight face\n",
    "* Image source: https://www.kaggle.com/c/state-farm-distracted-driver-detection/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_01 = \"https://raw.githubusercontent.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/main/resources/statefarm-image-01.png\"\n",
    "image_02 = \"https://raw.githubusercontent.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/main/resources/statefarm-image-02.png\"\n",
    "face_portrait = \"https://raw.githubusercontent.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/main/resources/face-portrait.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_in_cell(face_portrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_in_cell(image_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_in_cell(image_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Face - Detect API with detection model and face attribute parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Face form an image\n",
    "def detect_face_with_attributes_01_from_any_url(selected_image_url):\n",
    "    detected_faces = face_client.face.detect_with_url(url=selected_image_url, \n",
    "                                                      detection_model='detection_03',\n",
    "                                                     return_face_attributes=[\n",
    "                    'headpose',\n",
    "                    'mask'\n",
    "                ])\n",
    "    if not detected_faces:\n",
    "        raise Exception('No face detected from image {}'.format(selected_image_url))        \n",
    "    print('Total face(s) detected  from {}'.format(str(len(detected_faces))))\n",
    "    return detected_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Face - Detect API with detection model and different face attribute parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Face form an image\n",
    "def detect_face_with_attributes_02_from_any_url(selected_image_url):\n",
    "    detected_faces = face_client.face.detect_with_url(url=selected_image_url, \n",
    "                                                     return_face_attributes=[\n",
    "                    'age',\n",
    "                    'gender',\n",
    "                    'headPose',\n",
    "                    'smile',\n",
    "                    'facialHair',\n",
    "                    'glasses',\n",
    "                    'emotion',\n",
    "                    'hair',\n",
    "                    'makeup',\n",
    "                    'occlusion',\n",
    "                    'accessories',\n",
    "                    'blur',\n",
    "                    'exposure',\n",
    "                    'noise'\n",
    "                ])\n",
    "    if not detected_faces:\n",
    "        raise Exception('No face detected from image {}'.format(selected_image_url))        \n",
    "    print('Total face(s) detected  from {}'.format(str(len(detected_faces))))\n",
    "    return detected_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_faces_00_object = detect_face_with_attributes_01_from_any_url(face_portrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_00_object: \n",
    "    print (face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_00_object: \n",
    "    print (face.face_attributes.head_pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same detection model with a different image: Image_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_faces_01_object = detect_face_with_attributes_01_from_any_url(image_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_01_object: \n",
    "        print (face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_01_object: \n",
    "        print (face.face_attributes.head_pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same detection model with a different image: Image_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_faces_02_object = detect_face_with_attributes_01_from_any_url(image_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_02_object: \n",
    "        print (face.face_attributes.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_02_object: \n",
    "        print (face.face_attributes.head_pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same Image Different Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_faces_001_object = detect_face_with_attributes_02_from_any_url(face_portrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_001_object: \n",
    "        print (face.face_attributes.head_pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting different face attributes from the face detect API result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_001_object: \n",
    "    print (face.face_attributes.age)\n",
    "    print (face.face_attributes.emotion)\n",
    "    print (face.face_attributes.gender)\n",
    "    print (face.face_attributes.accessories)\n",
    "    print (face.face_attributes.smile)\n",
    "    print (face.face_attributes.hair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Hair type and color face attributes from the face detect API result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_001_object: \n",
    "    print (face.face_attributes.hair)\n",
    "    print (len(face.face_attributes.hair.hair_color))\n",
    "    print (face.face_attributes.hair.hair_color[0])\n",
    "    for each_hair_color in face.face_attributes.hair.hair_color:\n",
    "        print (each_hair_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_02_object: \n",
    "        print (face.face_attributes.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_01_object: \n",
    "        print (face.face_attributes.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
