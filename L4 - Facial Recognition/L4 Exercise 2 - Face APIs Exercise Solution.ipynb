{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please install the required Python modules/SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! activate ai-azure-c1\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/opt/conda/envs/ai-azure-c1/lib/python3.8/site-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This demo uses latest pillow package to show the rectangle around the face so please upgrade the pillow package using the command as below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow==8.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Useful Python Libraries or package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilitiy Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_in_cell(face_url):\n",
    "    response = requests.get(face_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_object_in_cell(image_object):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(image_object)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKEN FROM THE Azure SDK Sample\n",
    "# Convert width height to a point in a rectangle\n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "    \n",
    "    return ((left, top), (right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawFaceRectangles(source_file, detected_face_object) :\n",
    "    # Download the image from the url\n",
    "    response = requests.get(source_file)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    # Draw a red box around every detected faces\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for face in detected_face_object:\n",
    "        draw.rectangle(getRectangle(face), outline='red', width = 10)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Specific Azure Resources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = \"ENTER FACE SERVICE RESOURCE KEY\"\n",
    "ENDPOINT = \"ENTER FACE SERVICE RESOURCE ENDPOINT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace image URLs here\n",
    "* Here I am including the images I used in the demo earlier.\n",
    "* You can use your own images by replacing the image URL in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_01 = \"https://raw.githubusercontent.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/main/resources/face-portrait.jpg\"\n",
    "image_02 = \"https://github.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/blob/main/resources/human-face1.jpg?raw=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_in_cell(image_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_in_cell(image_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Face - Detect API with detection model and face attribute parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Face from an image\n",
    "def detect_face_with_attributes_02_from_any_url(selected_image_url):\n",
    "    detected_faces = face_client.face.detect_with_url(url=selected_image_url, \n",
    "                                                     return_face_attributes=[\n",
    "                    'age',\n",
    "                    'gender',\n",
    "                    'headPose',\n",
    "                    'smile',\n",
    "                    'facialHair',\n",
    "                    'glasses',\n",
    "                    'emotion',\n",
    "                    'hair',\n",
    "                    'makeup',\n",
    "                    'occlusion',\n",
    "                    'accessories',\n",
    "                    'blur',\n",
    "                    'exposure',\n",
    "                    'noise'\n",
    "                ])\n",
    "    if not detected_faces:\n",
    "        raise Exception('No face detected from image {}'.format(selected_image_url))        \n",
    "    print('Total face(s) detected  from {}'.format(str(len(detected_faces))))\n",
    "    return detected_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image_01 with Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_faces_01_object = detect_face_with_attributes_02_from_any_url(image_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_01_object: \n",
    "        print (face.face_attributes.head_pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same detection model with a different image: Image_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_faces_02_object = detect_face_with_attributes_02_from_any_url(image_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_02_object: \n",
    "        print (face.face_attributes.head_pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting different face attributes from the Face Detect API result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_01_object: \n",
    "    print (face.face_attributes.age)\n",
    "    print (face.face_attributes.emotion)\n",
    "    print (face.face_attributes.gender)\n",
    "    print (face.face_attributes.accessories)\n",
    "    print (face.face_attributes.smile)\n",
    "    print (face.face_attributes.hair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Hair type and color attributes from the Face Detect API result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in detected_faces_01_object: \n",
    "    for each_hair_color in face.face_attributes.hair.hair_color:\n",
    "        print (each_hair_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Find Similar API with 2 faces detected using Face Detect API\n",
    "\n",
    "### Replace image URL here\n",
    "* Here I am including the images I used in the demo earlier.\n",
    "* You can use your own images by replacing the image URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_image = \"https://raw.githubusercontent.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/main/resources/obama-photo.jpg\"\n",
    "group_image = \"https://raw.githubusercontent.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/main/resources/obama-inauguration.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_in_cell(face_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_in_cell(group_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Face from an image\n",
    "def detect_face_from_any_url(selected_image):\n",
    "    detected_faces = face_client.face.detect_with_url(url=selected_image, detection_model='detection_03')\n",
    "    if not detected_faces:\n",
    "        raise Exception('No face detected from image {}'.format(single_image_name))        \n",
    "    print('Total face(s) detected  from {}'.format(str(len(detected_faces))))\n",
    "    return detected_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_faces_from_detected_face_object(detected_faces_object):\n",
    "    print('We found total {} face(s) in selected face detected object.'.format(str(len(detected_faces_object))))\n",
    "    for face in detected_faces_object: \n",
    "        print (face.face_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_faces_object = detect_face_from_any_url(face_image)\n",
    "list_all_faces_from_detected_face_object(source_faces_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawFaceRectangles(face_image, source_faces_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_faces_object = detect_face_from_any_url(group_image)\n",
    "list_all_faces_from_detected_face_object(group_faces_object)\n",
    "drawFaceRectangles(group_image, group_faces_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source FACE ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in source_faces_object:\n",
    "    source_image_face_id = face.face_id\n",
    "print(source_image_face_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group FACE ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_image_face_IDs_list = list(map(lambda x: x.face_id, group_faces_object))\n",
    "print('All faces in the group list {}'.format(str(len(group_image_face_IDs_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_faces = face_client.face.find_similar(face_id=source_image_face_id, face_ids=group_image_face_IDs_list)\n",
    "for similar_face in similar_faces:\n",
    "    print(similar_face.face_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_face_object(similar_faces, group_faces_object):\n",
    "    for face in similar_faces:\n",
    "        first_image_face_ID = face.face_id\n",
    "        face_info = next(x for x in group_faces_object if x.face_id == first_image_face_ID)\n",
    "        if face_info:\n",
    "            return face_info\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_face_info = get_similar_face_object(similar_faces, group_faces_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing similar face in the group photo from the source image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(group_image)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "# Draw a red box around every detected faces\n",
    "draw = ImageDraw.Draw(img)\n",
    "draw.rectangle(getRectangle(similar_face_info), outline='red', width = 10)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Verify API with 2 faces detected using Face Detect API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_result_same = face_client.face.verify_face_to_face(source_image_face_id, similar_face.face_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Faces from {} & {} are of the same person, with confidence: {}'.format(face_image, group_image, verify_result_same.confidence))\n",
    "if verify_result_same.is_identical:\n",
    "      print(\"Faces are Similar\")\n",
    "else:\n",
    "      print('Faces from {} & {} are of a different person, with confidence: {}'.format(face_image, group_image, verify_result_same.confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
